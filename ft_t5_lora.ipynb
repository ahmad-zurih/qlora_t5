{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635a1e40-2987-41a1-b51e-07932f064f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import gc\n",
    "\n",
    "dataset = load_dataset(\"wmt20_mlqe_task1\", \"en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57075ba0-da25-4895-9278-d4dca911045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_languages(examples):\n",
    "    targets = [ex[\"de\"] for ex in examples[\"translation\"]]\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    return {\"inputs\": inputs, \"targets\": targets}\n",
    "\n",
    "dataset = dataset.map(extract_languages, batched=True, remove_columns=['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'])\n",
    "dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0ca776-dc5f-4f1b-8728-501f04e1ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data is: 7000\n",
      "Length of validation data is: 1000\n",
      "Length of testing data is: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = dataset[\"train\"]\n",
    "validation = dataset[\"validation\"]\n",
    "testing = dataset[\"test\"]\n",
    "\n",
    "print(f\"Length of training data is: {len(training)}\")\n",
    "print(f\"Length of validation data is: {len(validation)}\")\n",
    "print(f\"Length of testing data is: {len(testing)}\")\n",
    "\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6974c12c-57da-48c2-8dd0-621c920ff95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Memory used after loading the model: 465.05 MB\n",
      "GPU Memory used after loading the model: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "\n",
    "# Function to get memory usage in megabytes\n",
    "def memory_usage_mb():\n",
    "    return psutil.Process().memory_info().rss / (1024 ** 2)\n",
    "\n",
    "# Function to get GPU memory usage in MB\n",
    "def gpu_memory_usage_mb():\n",
    "    torch.cuda.synchronize()  # Wait for all operations on the GPU to complete\n",
    "    return torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "\n",
    "\n",
    "# Measure memory before loading the model\n",
    "memory_before = memory_usage_mb()\n",
    "gpu_memory_before = gpu_memory_usage_mb()\n",
    "\n",
    "tokenizer_q = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model_q = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Measure memory after loading the model\n",
    "memory_after = memory_usage_mb()\n",
    "gpu_memory_after = gpu_memory_usage_mb()\n",
    "\n",
    "# Calculate and print the difference in memory usage\n",
    "print(f\"System Memory used after loading the model: {memory_after - memory_before:.2f} MB\")\n",
    "print(f\"GPU Memory used after loading the model: {gpu_memory_after - gpu_memory_before:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52229f6c-24b9-4e3f-8c12-52d34d0c3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model_q.gradient_checkpointing_enable()\n",
    "model_q = prepare_model_for_kbit_training(model_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3210f82-9a62-402c-94d9-5b5f58ec4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee05e086-3d9e-47bb-80e8-570489ce0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60866297-7fa7-4e60-9f61-12d23953a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294912 || all params: 60801536 || trainable%: 0.4850403779272945\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=32,  \n",
    "    lora_dropout=0.05, \n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model_q = get_peft_model(model_q, config)\n",
    "print_trainable_parameters(model_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ecc4bf-f5bd-4a8e-95ba-c281fd767de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"inputs\"\n",
    "target_lang = \"targets\"\n",
    "prefix = \"translate English eo German: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    model_inputs = tokenizer_q(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    with tokenizer_q.as_target_tokenizer():\n",
    "        labels = tokenizer_q(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_training_data = training.map(preprocess_function, batched=True)\n",
    "validation_training_data = validation.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73521fb5-7701-4441-b6fb-8b1aca6f9d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 18:54:12.888208: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-21 18:54:12.980023: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 18:54:13.587564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer_q, model=model_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e13b82d-fe9f-46fa-a5ff-17e05792a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5256' max='5256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5256/5256 09:23, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.009200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.947100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.933400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.919100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.931400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.920200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5256, training_loss=0.9361332729345406, metrics={'train_runtime': 564.2183, 'train_samples_per_second': 148.879, 'train_steps_per_second': 9.316, 'total_flos': 1074345608478720.0, 'train_loss': 0.9361332729345406, 'epoch': 12.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results_3\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=12,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_q,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training_data,\n",
    "    eval_dataset=validation_training_data,\n",
    "    tokenizer=tokenizer_q,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1c4e9a-7d32-4522-a27d-adbf98ed5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./en_de_model_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0509fa41-cf42-4310-8710-f365ba9b4aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the lora fine tuned t5 model is: 47.243537078267856\n",
      "Execution time: 340.40728187561035 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import sacrebleu\n",
    "import time\n",
    "\n",
    "\n",
    "def translator_pipeline(model_name, tokenizer_name):\n",
    "    translator = pipeline(\"translation_en_to_de\", model=model_name, tokenizer=tokenizer_name)\n",
    "    return translator\n",
    "\n",
    "def translate_and_evaluate(test_dataset):\n",
    "    translations = []\n",
    "    references = []\n",
    "\n",
    "    for item in test_dataset:\n",
    "        # Translate each sentence\n",
    "        english_sentence = item['inputs']\n",
    "        german_translation = translator(english_sentence, max_length=128, truncation=True)[0]['translation_text']\n",
    "\n",
    "        # Append the result and the reference translation\n",
    "        translations.append(german_translation)\n",
    "        references.append(item['targets'])\n",
    "\n",
    "    return translations, references\n",
    "\n",
    "\n",
    "# Function to calculate BLEU score using SacreBLEU\n",
    "def calculate_bleu_score(translations, references):\n",
    "    bleu = sacrebleu.corpus_bleu(translations, [references])\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"./en_de_model_lora\"  \n",
    "our_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "our_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "translator = translator_pipeline(our_model, our_tokenizer)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "translations, references = translate_and_evaluate(testing)\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_score = calculate_bleu_score(translations, references)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"BLEU score for the lora fine tuned t5 model is: {bleu_score}\")\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898d3c7-a4bb-493e-bad6-366edf9aefd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
