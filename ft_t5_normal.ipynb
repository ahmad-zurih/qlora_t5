{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350979b9-2118-4290-91b7-b97df385fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import gc\n",
    "\n",
    "dataset = load_dataset(\"wmt20_mlqe_task1\", \"en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d788f4f-0779-4198-9913-badbb1885348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'],\n",
      "        num_rows: 7000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "column names are: \n",
      "{'train': ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'], 'test': ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'], 'validation': ['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas']}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "columns = dataset.column_names\n",
    "print(f'column names are: \\n{columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af20c622-ab1d-4382-9e13-566f2f0ed32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_languages(examples):\n",
    "    targets = [ex[\"de\"] for ex in examples[\"translation\"]]\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    return {\"inputs\": inputs, \"targets\": targets}\n",
    "\n",
    "dataset = dataset.map(extract_languages, batched=True, remove_columns=['segid', 'translation', 'scores', 'mean', 'z_scores', 'z_mean', 'model_score', 'doc_id', 'nmt_output', 'word_probas'])\n",
    "dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d68933f-e2cc-48d7-be66-0d8355375673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data is: 7000\n",
      "Length of validation data is: 1000\n",
      "Length of testing data is: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = dataset[\"train\"]\n",
    "validation = dataset[\"validation\"]\n",
    "testing = dataset[\"test\"]\n",
    "\n",
    "print(f\"Length of training data is: {len(training)}\")\n",
    "print(f\"Length of validation data is: {len(validation)}\")\n",
    "print(f\"Length of testing data is: {len(testing)}\")\n",
    "\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28bd69f5-5fc0-4e79-9925-924f7fa59004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example of how the data look like now:\n",
      " {'inputs': 'They engaged in crossfire at Guamaní River Bridge, Coamo and Silva Heights and finally at the Battle of Asomante.', 'targets': 'Sie verübten Kreuzfeuer an der Guamaní River Bridge, Coamo und Silva Heights und schließlich an der Schlacht von Asomante.'}\n",
      "They engaged in crossfire at Guamaní River Bridge, Coamo and Silva Heights and finally at the Battle of Asomante.\n",
      "Sie verübten Kreuzfeuer an der Guamaní River Bridge, Coamo und Silva Heights und schließlich an der Schlacht von Asomante.\n"
     ]
    }
   ],
   "source": [
    "print(f\"example of how the data look like now:\\n {training[5]}\")\n",
    "print(training[5][\"inputs\"])\n",
    "print(training[5][\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941d5da6-c6fe-45d5-9ae5-b9af8a0f9de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Memory used after loading the model: 244.15 MB\n",
      "GPU Memory used after loading the model: 230.81 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Function to get memory usage in megabytes\n",
    "def memory_usage_mb():\n",
    "    return psutil.Process().memory_info().rss / (1024 ** 2)\n",
    "\n",
    "# Function to get GPU memory usage in MB\n",
    "def gpu_memory_usage_mb():\n",
    "    torch.cuda.synchronize()  # Wait for all operations on the GPU to complete\n",
    "    return torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "\n",
    "# Measure memory before loading the model\n",
    "memory_before = memory_usage_mb()\n",
    "gpu_memory_before = gpu_memory_usage_mb()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", device_map='cuda')\n",
    "\n",
    "# Measure memory after loading the model\n",
    "memory_after = memory_usage_mb()\n",
    "gpu_memory_after = gpu_memory_usage_mb()\n",
    "\n",
    "# Calculate and print the difference in memory usage\n",
    "print(f\"System Memory used after loading the model: {memory_after - memory_before:.2f} MB\")\n",
    "print(f\"GPU Memory used after loading the model: {gpu_memory_after - gpu_memory_before:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630add9e-863b-432b-adc3-8699511bf996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defeddbc5e00409eb6b4c7082cb8e7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "source_lang = \"inputs\"\n",
    "target_lang = \"targets\"\n",
    "prefix = \"translate English eo German: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_training_data = training.map(preprocess_function, batched=True)\n",
    "validation_training_data = validation.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a99b89e-c13f-42d4-b5c2-92d63ac8c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': 'José Ortega y Gasset visited Husserl at Freiburg in 1934.', 'targets': '1934 besuchte José Ortega y Gasset Husserl in Freiburg.', 'input_ids': [13959, 1566, 3, 15, 32, 2968, 10, 26816, 4366, 12029, 3, 63, 6435, 2244, 5251, 13674, 7, 49, 40, 44, 30498, 16, 28828, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [28828, 22361, 15, 26816, 4366, 12029, 3, 63, 6435, 2244, 13674, 7, 49, 40, 16, 30498, 5, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b306e108-d684-4c26-b5ca-05828d981995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3deaf175-b051-4305-8cea-1067b04a3c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5256' max='5256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5256/5256 10:41, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.660553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.649570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>0.642341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.867100</td>\n",
       "      <td>0.636562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>0.632857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.823300</td>\n",
       "      <td>0.629307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>0.627437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.625632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.624520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>0.624075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.623456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.623251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5256, training_loss=0.8348093540882593, metrics={'train_runtime': 642.664, 'train_samples_per_second': 130.706, 'train_steps_per_second': 8.178, 'total_flos': 1067201825341440.0, 'train_loss': 0.8348093540882593, 'epoch': 12.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results_1\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=12,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training_data,\n",
    "    eval_dataset=validation_training_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad4776f-d05a-4a87-beb9-4e31349758c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./en_de_model_normal_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7939ca0e-98e1-4f13-b0b6-a509a70f809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the normally fine-tuned t5 model is: 49.42898092092283\n",
      "Execution time: 326.48990988731384 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import sacrebleu\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def translator_pipeline(model_name, tokenizer_name):\n",
    "    translator = pipeline(\"translation_en_to_de\", model=model_name, tokenizer=tokenizer_name)\n",
    "    return translator\n",
    "\n",
    "def translate_and_evaluate(test_dataset):\n",
    "    translations = []\n",
    "    references = []\n",
    "\n",
    "    for item in test_dataset:\n",
    "        # Translate each sentence\n",
    "        english_sentence = item['inputs']\n",
    "        german_translation = translator(english_sentence, max_length=128, truncation=True)[0]['translation_text']\n",
    "\n",
    "        # Append the result and the reference translation\n",
    "        translations.append(german_translation)\n",
    "        references.append(item['targets'])\n",
    "\n",
    "    return translations, references\n",
    "\n",
    "\n",
    "# Function to calculate BLEU score using SacreBLEU\n",
    "def calculate_bleu_score(translations, references):\n",
    "    bleu = sacrebleu.corpus_bleu(translations, [references])\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"./en_de_model_normal_ft\"  \n",
    "our_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "our_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "translator = translator_pipeline(our_model, our_tokenizer)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "translations, references = translate_and_evaluate(testing)\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_score = calculate_bleu_score(translations, references)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"BLEU score for the normally fine-tuned t5 model is: {bleu_score}\")\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f50c53-37e5-4e74-9e38-6719876cf2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
